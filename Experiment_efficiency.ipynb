{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook, get_H_transform\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pickle as pkl\n",
    "from top_walks import *\n",
    "from utils import *\n",
    "from IPython.display import SVG, display\n",
    "from baseline_comp import *\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA2motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_model_dirs = [['BA-2motif','gin-3-ba2motif.torch'],\n",
    "                      ['BA-2motif','gin-5-ba2motif.torch'],\n",
    "                      ['BA-2motif','gin-7-ba2motif.torch'],\n",
    "                      ['MUTAG', 'gin-3-mutag.torch'],\n",
    "                      ['Mutagenicity', 'gin-3-mutagenicity.torch'],\n",
    "                      ['REDDIT-BINARY', 'gin-5-reddit.torch'],\n",
    "                      ['Graph-SST2', 'gcn-3-sst2graph.torch']]\n",
    "dataset, model_dir = dataset_model_dirs[0]\n",
    "graphs, pos_idx, neg_idx = load_data(dataset)\n",
    "nn = torch.load('models/'+model_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a function of K, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_res = []\n",
    "for L in range(2,8):\n",
    "    model_dir = f\"gin-{L}-ba2motif.torch\"\n",
    "    nn = torch.load('models/'+model_dir)\n",
    "\n",
    "    g = graphs[0]\n",
    "    pred = nn.forward(g.get_adj(),H0=g.node_features).argmax()\n",
    "    H, transforms = get_H_transform(g.get_adj(),nn,H0=g.node_features,gammas=None, mode='gamma')\n",
    "    init_rel = np.zeros_like(H)\n",
    "    init_rel[:, pred] = H[:, pred]\n",
    "\n",
    "    time_accumulate_1 = 0\n",
    "    time_accumulate_2 = 0\n",
    "    iteration_num = 5\n",
    "    for _ in tqdm(range(iteration_num)):\n",
    "        time_a = time.time()\n",
    "\n",
    "        walk_rels = {}\n",
    "        for i, walk in enumerate(itertools.product(np.arange(g.nbnodes),repeat=L+1)):\n",
    "            if i == 1000: break\n",
    "            rel = walk_rel(transforms, init_rel, walk, mode=\"node\")\n",
    "            walk_rels[tuple(walk)] = rel\n",
    "        \n",
    "        time_tmp = time.time() - time_a\n",
    "        time_tmp = time_tmp / 1000 * (g.nbnodes ** (L+1))\n",
    "\n",
    "        time_a = time.time()\n",
    "        top_walk = max(walk_rels.items(), key=lambda item: item[1])[0]\n",
    "        time_accumulate_1 += time_tmp + time.time() - time_a\n",
    "\n",
    "        time_a = time.time()\n",
    "        top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=1, lrp_mode=\"gamma\", \n",
    "                negative_transition_strategy='none', mode=\"node\", transforms=transforms, H=init_rel)\n",
    "        time_accumulate_2 += time.time() - time_a\n",
    "\n",
    "    time_res.append([L, time_accumulate_1/iteration_num, time_accumulate_2/iteration_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "num_layers = np.arange(2,8)\n",
    "model_times = np.array(time_res)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "plt.rc('legend', fontsize=14.5) \n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax1.set_ylabel(\"Time (s)\")\n",
    "ax2.set_xlabel(r'$L$')\n",
    "plt.xticks(num_layers, [str(i) if i % 2 == 1 else '' for i in range(2,len(model_times)+2)])\n",
    "\n",
    "ax1.plot(num_layers, model_times[:,1], 'b--')\n",
    "line2, = ax1.plot(num_layers, [0]*len(num_layers), 'r-')\n",
    "ax1.legend(['GNN-LRP naive', 'AMP-ave'])\n",
    "line2.remove()\n",
    "ax2.plot(num_layers, model_times[:,1], 'b--')\n",
    "ax2.plot(num_layers, model_times[:,2], 'r-')\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.005)  # outliers only\n",
    "ax2.set_ylim(-0,0.005)\n",
    "\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,0), useMathText=True)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_L.svg', dpi=600, format='svg', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphs[0]\n",
    "pred = nn.forward(g.get_adj(),H0=g.node_features).argmax()\n",
    "H, transforms = get_H_transform(g.get_adj(),nn,H0=g.node_features,gammas=None, mode='gamma')\n",
    "init_rel = np.zeros_like(H)\n",
    "init_rel[:, pred] = H[:, pred]\n",
    "\n",
    "time_accumulate_1 = 0\n",
    "time_accumulate_2 = 0\n",
    "iteration_num = 5\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    walk_rels = {}\n",
    "    for walk in itertools.product(np.arange(g.nbnodes),np.arange(g.nbnodes),np.arange(g.nbnodes),np.arange(g.nbnodes)):\n",
    "        rel = walk_rel(transforms, init_rel, walk, mode=\"node\")\n",
    "        walk_rels[tuple(walk)] = rel\n",
    "    \n",
    "    time_tmp = time.time() - time_a\n",
    "\n",
    "    time_a = time.time()\n",
    "    top_walk = max(walk_rels.items(), key=lambda item: item[1])[0]\n",
    "    time_accumulate_1 += time_tmp + time.time() - time_a\n",
    "\n",
    "    time_a = time.time()\n",
    "    sorted_walk_rels = sorted(walk_rels.items(), key=lambda item: item[1], reverse=True)\n",
    "    time_accumulate_2 += time_tmp + time.time() - time_a\n",
    "\n",
    "print(time_accumulate_1/iteration_num, time_accumulate_2/iteration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "    top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=1, lrp_mode=\"gamma\", \n",
    "            negative_transition_strategy='none', mode=\"node\", transforms=transforms, H=init_rel)\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "    top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=100, lrp_mode=\"gamma\", \n",
    "            negative_transition_strategy='none', mode=\"node\", transforms=transforms, H=init_rel)\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "    top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=1000, lrp_mode=\"gamma\", \n",
    "            negative_transition_strategy='none', mode=\"node\", transforms=transforms, H=init_rel)\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "\n",
    "    top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=25, lrp_mode=\"\", mode=\"node\", transforms=transforms, H=init_rel)\n",
    "    node_rel = {}\n",
    "    for walk in top_max_walks:\n",
    "        for node in walk[0]:\n",
    "            if node not in node_rel: node_rel[node] = walk[1]\n",
    "            else: node_rel[node] += walk[1]\n",
    "        \n",
    "        if len(node_rel) < 5: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1])]\n",
    "        else: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "\n",
    "    top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=25, lrp_mode=\"\", mode=\"neuron\", transforms=transforms, H=init_rel)\n",
    "    node_rel = {}\n",
    "    for walk in top_max_walks:\n",
    "        for node in walk[0]:\n",
    "            if node not in node_rel: node_rel[node] = walk[1]\n",
    "            else: node_rel[node] += walk[1]\n",
    "        \n",
    "        if len(node_rel) < 5: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1])]\n",
    "        else: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    max_S = None\n",
    "    max_rel = -float('inf')\n",
    "    for S in itertools.combinations(range(25), 5):\n",
    "        rel = subgraph_mp_transcription(nn, g, S, 0., H=H, transforms=transforms)\n",
    "        if rel > max_rel:\n",
    "            max_S = S\n",
    "            max_rel = rel\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_size = 5\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    fo_gb = get_fo_gb(nn, g).tolist()\n",
    "    subgraph_gb = fo_gb[:subgraph_size]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    fo_cam = get_fo_cam(nn, g).tolist()\n",
    "    subgraph_cam = fo_cam[:subgraph_size]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    R = gnnexplainer(g, nn, g.node_features, verbose=False)\n",
    "    fo_gnnexpl = get_fo_gnnexpl(R)\n",
    "    subgraph_gnnexpl = fo_gnnexpl[:subgraph_size]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutagenicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, model_dir = dataset_model_dirs[4]\n",
    "graphs, pos_idx, neg_idx = load_data(dataset)\n",
    "nn = torch.load('models/'+model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_res = []\n",
    "L = 3\n",
    "K = 1\n",
    "\n",
    "for g in tqdm(graphs):\n",
    "    # g = graphs[0]\n",
    "    pred = nn.forward(g.get_adj(),H0=g.node_features).argmax()\n",
    "    H, transforms = get_H_transform(g.get_adj(),nn,H0=g.node_features,gammas=None, mode='gamma')\n",
    "    init_rel = np.zeros_like(H)\n",
    "    init_rel[:, pred] = H[:, pred]\n",
    "\n",
    "    time_accumulate_1 = 0\n",
    "    time_accumulate_2 = 0\n",
    "    iteration_num = 1\n",
    "    for _ in (range(iteration_num)):\n",
    "        time_a = time.time()\n",
    "\n",
    "        walk_rels = {}\n",
    "        i = 0\n",
    "        for walk in itertools.product(np.arange(g.nbnodes),repeat=L+1):\n",
    "            if  i == 100: break\n",
    "            rel = walk_rel(transforms, init_rel, walk, mode=\"node\")\n",
    "            walk_rels[tuple(walk)] = rel\n",
    "            i += 1\n",
    "        \n",
    "        time_tmp = (time.time() - time_a) / 100 * (g.nbnodes ** (L+1))\n",
    "        # print(time_tmp)\n",
    "\n",
    "        time_a = time.time()\n",
    "        sorted_walk_rels = sorted(walk_rels.items(), key=lambda item: item[1], reverse=True)[:K]\n",
    "        time_accumulate_1 += time_tmp + time.time() - time_a\n",
    "\n",
    "        time_a = time.time()\n",
    "        top_max_walks, top_min_walks = topk_walks(g, nn, num_walks=K, lrp_mode=\"gamma\", \n",
    "                negative_transition_strategy='none', mode=\"node\", transforms=transforms, H=init_rel)\n",
    "        time_accumulate_2 += time.time() - time_a\n",
    "\n",
    "    time_res.append([g.nbnodes, time_accumulate_1/iteration_num, time_accumulate_2/iteration_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "plt.rc('legend', fontsize=14.5) \n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax1.set_ylabel(\"Time (s)\")\n",
    "ax2.set_xlabel(r'$M$')\n",
    "\n",
    "ax1.plot(time_res_M_mean.index.tolist(), time_res_M_mean['exhaustive'], 'b--')\n",
    "line2, = ax1.plot(time_res_M_mean.index.tolist(), [0]*len(time_res_M_mean), 'r-')\n",
    "line2.remove()\n",
    "ax2.plot(time_res_M_mean.index.tolist(), time_res_M_mean['exhaustive'], 'b--')\n",
    "ax2.plot(time_res_M_mean.index.tolist(), time_res_M_mean['ours'], 'r-')\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.51)  # outliers only\n",
    "ax2.set_ylim(-0,0.5)\n",
    "ax2.set_xlim(1,time_res_M_mean.index.max())\n",
    "\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_M.svg', dpi=600, format='svg', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "from infection_utils import get_rel_components, approx_most_rel_walk, plot_n_hop_infect_graph, walk_to_walk_edges, walk_to_walk_edges_set, approx_top_k_walk\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/gcn-4-infection-sir_100_many_init_patient.torch\",'rb') as f:\n",
    "    model = pkl.load(f)\n",
    "with open(\"datasets/infection-sir/dataset_100.pt\",'rb') as f:\n",
    "    dataset = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "for d in dataset[:80]:\n",
    "    train_set.append(d)\n",
    "test_set = []\n",
    "for d in dataset[80:]:\n",
    "    test_set.append(d)\n",
    "\n",
    "INIT_INFECT_RATE = 0.02\n",
    "INFECTION_RATE = 0.6\n",
    "CURE_RATE = 0.\n",
    "IMMUNE_RATE = 1\n",
    "\n",
    "SUSPECTFUL = 0\n",
    "INFECTED = 1\n",
    "IMMUNED = 2\n",
    "\n",
    "zero_patient = False\n",
    "np.random.seed(0)\n",
    "\n",
    "steps = 4\n",
    "for data in train_set + test_set:\n",
    "    data.num_classes = 2\n",
    "    del data.unique_solution_nodes\n",
    "    del data.unique_solution_explanations\n",
    "\n",
    "    A = to_dense_adj(data.edge_index)[0]\n",
    "    \n",
    "    if zero_patient:\n",
    "        data.x = torch.zeros_like(data.x)\n",
    "        data.x[:,1] = 1\n",
    "        data.x[0,0] = 1\n",
    "        data.x[0,1] = 0\n",
    "    else:\n",
    "        init_infect_rate_ = np.random.rand() * INIT_INFECT_RATE\n",
    "        x = torch.tensor([int(np.random.rand() < init_infect_rate_) for _ in range(data.num_nodes)])\n",
    "        data.x = torch.column_stack([x, 1*(x != 1)]).float()\n",
    "    \n",
    "    x_state = torch.zeros(data.num_nodes)\n",
    "    x_state[torch.where(data.x[:,0]==1)] = INFECTED\n",
    "\n",
    "    infection_chains = {}\n",
    "    for node in range(data.num_nodes):\n",
    "        if x_state[node] == INFECTED:\n",
    "            infection_chains[node] = [node]\n",
    "\n",
    "    for step in range(steps):\n",
    "        I_nodes = torch.where(x_state==INFECTED)[0].tolist()\n",
    "        for I_node in I_nodes:\n",
    "            for node in A[I_node].nonzero().flatten().tolist():\n",
    "                if node in I_nodes:\n",
    "                    continue\n",
    "\n",
    "                if np.random.rand() < INFECTION_RATE:\n",
    "                    if x_state[node] == IMMUNED:\n",
    "                        if np.random.rand() < 1 - IMMUNE_RATE:\n",
    "                            x_state[node] = INFECTED\n",
    "                            infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "                    else:\n",
    "                        x_state[node] = INFECTED\n",
    "                        infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "            \n",
    "            if np.random.rand() < CURE_RATE:\n",
    "                x_state[I_node] = IMMUNED\n",
    "                del infection_chains[I_node]\n",
    "        \n",
    "    data.infection_chains = infection_chains.copy()\n",
    "    data.y = (x_state==INFECTED) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = torch.linspace(4, 1, 4), normalize=False)\n",
    "    real_top_k_max_walks_rels, _ = approx_top_k_walk(1, 7, data, model, rel_components, X_fc, A, verbose=False)\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = torch.linspace(4, 1, 4), normalize=False)\n",
    "    real_top_k_max_walks_rels, _ = approx_top_k_walk(100, 7, data, model, rel_components, X_fc, A, verbose=False)\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in tqdm(range(iteration_num)):\n",
    "    time_a = time.time()\n",
    "\n",
    "    rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = torch.linspace(4, 1, 4), normalize=False)\n",
    "    real_top_k_max_walks_rels, _ = approx_top_k_walk(1000, 7, data, model, rel_components, X_fc, A, verbose=False)\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "    \n",
    "print(time_accumulate / iteration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx_to_explain = 7\n",
    "target = data.y[node_idx_to_explain]\n",
    "init_rel = X_fc * (model.fc.state_dict()['weight'].T[:,target])\n",
    "init_rel[:node_idx_to_explain] = 0\n",
    "init_rel[min(node_idx_to_explain+1, init_rel.shape[0]):] = 0\n",
    "init_rel = init_rel/init_rel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_rel_infection(walk, init_rel, rel_components, A):\n",
    "    A_diag = torch.eye(A.shape[0])\n",
    "    R_Ii = init_rel[walk[-1]]\n",
    "    for i in range(1, 1+len(rel_components)):\n",
    "        W, U, X, denom = rel_components[-i]\n",
    "        J = walk[-i]\n",
    "        I = walk[-1-i]\n",
    "        R_denom_J = R_Ii / denom[J] # shape [j]\n",
    "        \n",
    "        R_Ii = X[I] * (A[I,J] * R_denom_J @ W.T + A_diag[I,J] * R_denom_J @ U.T) # shape [i]\n",
    "    rel = R_Ii.sum()\n",
    "\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate_1 = 0\n",
    "time_accumulate_2 = 0\n",
    "iteration_num = 5\n",
    "walk_rels = {}\n",
    "\n",
    "A = to_dense_adj(data.edge_index)[0]\n",
    "l1 = set(A[:, node_idx_to_explain].nonzero().flatten().tolist())\n",
    "l1.add(node_idx_to_explain)\n",
    "l2 = set(A[:, list(l1)].sum(axis=1).nonzero().flatten().tolist())\n",
    "l2.add(node_idx_to_explain)\n",
    "l3 = set(A[:, list(l2)].sum(axis=1).nonzero().flatten().tolist())\n",
    "l3.add(node_idx_to_explain)\n",
    "l4 = set(A[:, list(l3)].sum(axis=1).nonzero().flatten().tolist())\n",
    "l4.add(node_idx_to_explain)\n",
    "\n",
    "print(len(l4)*len(l3)*len(l2)*len(l1), 'possible walks')\n",
    "\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "\n",
    "    walk_rels = {}\n",
    "    for walk in tqdm(itertools.product(l4,l3,l2,l1)):\n",
    "        walk = list(walk) + [node_idx_to_explain]\n",
    "        rel = walk_rel_infection(walk, init_rel, rel_components, A)\n",
    "        walk_rels[tuple(walk)] = rel\n",
    "    \n",
    "    time_tmp = time.time() - time_a\n",
    "\n",
    "    time_a = time.time()\n",
    "    top_walk = max(walk_rels.items(), key=lambda item: item[1])[0]\n",
    "    time_accumulate_1 += time_tmp + time.time() - time_a\n",
    "\n",
    "    time_a = time.time()\n",
    "    sorted_walk_rels = sorted(walk_rels.items(), key=lambda item: item[1], reverse=True)\n",
    "    time_accumulate_2 += time_tmp + time.time() - time_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "\n",
    "    rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = torch.linspace(4, 1, 4), normalize=False)\n",
    "    real_top_k_max_walks_rels, _ = approx_top_k_walk(25, node_idx_to_explain, data, model, rel_components, X_fc, A, verbose=False)\n",
    "    \n",
    "    node_rel = {}\n",
    "    for walk in real_top_k_max_walks_rels:\n",
    "        for node in walk[0]:\n",
    "            if node not in node_rel: node_rel[node] = walk[1]\n",
    "            else: node_rel[node] += walk[1]\n",
    "        \n",
    "        if len(node_rel) < 5: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1])]\n",
    "        else: S = [item[0] for item in sorted(node_rel.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNNExplainer\n",
    "def sigm(z):\n",
    "    return torch.tanh(0.5*z)*0.5+0.5\n",
    "x_init, edge_index, edge_weight, y = data.x, data.edge_index, None, data.y\n",
    "pred = model.forward(edge_index=edge_index, x=data.x)[node_idx_to_explain].argmax()\n",
    "A = to_dense_adj(edge_index)[0]\n",
    "A_diag = torch.eye(A.shape[0])\n",
    "\n",
    "steps=500\n",
    "lr=0.5\n",
    "lambd=0.01\n",
    "verbose=False\n",
    "\n",
    "time_accumulate = 0\n",
    "for _ in range(iteration_num):\n",
    "    time_a = time.time()\n",
    "    \n",
    "    z = torch.ones(A.shape)*A*2\n",
    "    num_layer = 4\n",
    "    bar = tqdm(range(steps)) if verbose else range(steps)\n",
    "    for i in bar:\n",
    "        z.requires_grad_(True)\n",
    "        x = x_init\n",
    "\n",
    "        for i in range(len(model.convs)):\n",
    "            state_dict = model.convs[i].state_dict()\n",
    "            \n",
    "            W = state_dict['lin_rel.weight'].T \n",
    "            U = state_dict['lin_root.weight'].T \n",
    "            \n",
    "            out = (sigm(z) * A).T @ x\n",
    "            out = out @ W + state_dict['lin_rel.bias'] + x @ U\n",
    "            \n",
    "            x = F.relu(out)\n",
    "\n",
    "        x = x @ model.fc.state_dict()['weight'].T + model.fc.state_dict()['bias']\n",
    "        score = x[node_idx_to_explain][pred]\n",
    "\n",
    "        emp   = -score\n",
    "        reg   = lambd*((z)**2).sum() # torch.zeros((1,))   \n",
    "\n",
    "        if i in [j**3 for j in range(100)] and verbose: print('%5d %8.3f %8.3f'%(i,emp.item(),reg.item()))\n",
    "        \n",
    "        (emp+reg).backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = (z - lr*z.grad)\n",
    "        z.grad = None\n",
    "\n",
    "    S = get_fo_gnnexpl(z.data, topk = 25)[:5]\n",
    "\n",
    "    time_accumulate += time.time() - time_a\n",
    "\n",
    "print(time_accumulate / iteration_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sGNN-LRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65d5eb093fbec7e7bc52665d82a3cd76b3638a6de4797644d5d4a8277e42c4dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
