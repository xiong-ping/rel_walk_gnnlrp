{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook, get_H_transform\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pickle as pkl\n",
    "from top_walks import *\n",
    "from utils import *\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset\n",
    "-> Lukas Faber, Amin K. Moghaddam, and Roger Wattenhofer. 2021. When Comparing to Ground Truth is Wrong: On Evaluating GNN Explanation Methods. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD '21). Association for Computing Machinery, New York, NY, USA, 332â€“341. https://doi.org/10.1145/3447548.3467283\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# import mlflow\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "def create_infection_dataset(num_layers=4,size=10):\n",
    "    print(num_layers+2, \"classes\")\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(size):\n",
    "        max_dist = num_layers  # anything larger than max_dist has a far away label\n",
    "        g = nx.erdos_renyi_graph(1000, 0.004, directed=True)\n",
    "        N = len(g.nodes())\n",
    "        infected_nodes = random.sample(g.nodes(), 50)\n",
    "        g.add_node('X')  # dummy node for easier computation, will be removed in the end\n",
    "        for u in infected_nodes:\n",
    "            g.add_edge('X', u)\n",
    "        shortest_path_length = nx.single_source_shortest_path_length(g, 'X')\n",
    "        unique_solution_nodes = []\n",
    "        unique_solution_explanations = []\n",
    "        labels = []\n",
    "        features = np.zeros((N, 2))\n",
    "        for i in range(N):\n",
    "            if i == 'X':\n",
    "                continue\n",
    "            length = shortest_path_length.get(i, 100) - 1  # 100 is inf distance\n",
    "            labels.append(min(max_dist + 1, length))\n",
    "            col = 0 if i in infected_nodes else 1\n",
    "            features[i, col] = 1\n",
    "            if 0 < length <= max_dist:\n",
    "                path_iterator = iter(nx.all_shortest_paths(g, 'X', i))\n",
    "                unique_shortest_path = next(path_iterator)\n",
    "                if next(path_iterator, 0) != 0:\n",
    "                    continue\n",
    "                unique_shortest_path.pop(0)  # pop 'X' node\n",
    "                if len(unique_shortest_path) == 0:\n",
    "                    continue\n",
    "                unique_solution_explanations.append(unique_shortest_path)\n",
    "                unique_solution_nodes.append(i)\n",
    "        g.remove_node('X')\n",
    "        data = from_networkx(g)\n",
    "        data.x = torch.tensor(features, dtype=torch.float)\n",
    "        data.y = torch.tensor(labels)\n",
    "        data.unique_solution_nodes = unique_solution_nodes\n",
    "        data.unique_solution_explanations = unique_solution_explanations\n",
    "        data.num_classes = 1 + max_dist + 1\n",
    "        # print('created one')\n",
    "        dataset.append(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_infection_dataset(num_layers=4,size=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to SIR dataset\n",
    "\n",
    "- INFECTION_RATE: infection rate\n",
    "- CURE_RATE: cure rate\n",
    "- IMMUNE_RATE: immune rate, default 1\n",
    "\n",
    "Labels:\n",
    "- 0: Not infected\n",
    "- 1: Infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "for d in dataset[:80]:\n",
    "    train_set.append(d)\n",
    "test_set = []\n",
    "for d in dataset[80:]:\n",
    "    test_set.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_INFECT_RATE = 0.02\n",
    "INFECTION_RATE = 0.6\n",
    "CURE_RATE = 0.\n",
    "IMMUNE_RATE = 1\n",
    "\n",
    "SUSPECTFUL = 0\n",
    "INFECTED = 1\n",
    "IMMUNED = 2\n",
    "\n",
    "zero_patient = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4\n",
    "for data in train_set + test_set:\n",
    "    data.num_classes = 2\n",
    "    del data.unique_solution_nodes\n",
    "    del data.unique_solution_explanations\n",
    "\n",
    "    A = to_dense_adj(data.edge_index)[0]\n",
    "    \n",
    "    if zero_patient:\n",
    "        data.x = torch.zeros_like(data.x)\n",
    "        data.x[:,1] = 1\n",
    "        data.x[0,0] = 1\n",
    "        data.x[0,1] = 0\n",
    "    else:\n",
    "        init_infect_rate_ = np.random.rand() * INIT_INFECT_RATE\n",
    "        x = torch.tensor([int(np.random.rand() < init_infect_rate_) for _ in range(data.num_nodes)])\n",
    "        data.x = torch.column_stack([x, 1*(x != 1)]).float()\n",
    "    \n",
    "    x_state = torch.zeros(data.num_nodes)\n",
    "    x_state[torch.where(data.x[:,0]==1)] = INFECTED\n",
    "\n",
    "    infection_chains = {}\n",
    "    for node in range(data.num_nodes):\n",
    "        if x_state[node] == INFECTED:\n",
    "            infection_chains[node] = [node]\n",
    "\n",
    "    for step in range(steps):\n",
    "        I_nodes = torch.where(x_state==INFECTED)[0].tolist()\n",
    "        for I_node in I_nodes:\n",
    "            for node in A[I_node].nonzero().flatten().tolist():\n",
    "                if node in I_nodes:\n",
    "                    continue\n",
    "\n",
    "                if np.random.rand() < INFECTION_RATE:\n",
    "                    if x_state[node] == IMMUNED:\n",
    "                        if np.random.rand() < 1 - IMMUNE_RATE:\n",
    "                            x_state[node] = INFECTED\n",
    "                            infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "                    else:\n",
    "                        x_state[node] = INFECTED\n",
    "                        infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "            \n",
    "            if np.random.rand() < CURE_RATE:\n",
    "                x_state[I_node] = IMMUNED\n",
    "                del infection_chains[I_node]\n",
    "        \n",
    "    data.infection_chains = infection_chains.copy()\n",
    "    data.y = (x_state==INFECTED) * 1\n",
    "\n",
    "data = val_data\n",
    "data.num_classes = 2\n",
    "del data.unique_solution_nodes\n",
    "del data.unique_solution_explanations\n",
    "\n",
    "A = to_dense_adj(data.edge_index)[0]\n",
    "\n",
    "if zero_patient:\n",
    "    data.x = torch.zeros_like(data.x)\n",
    "    data.x[:,1] = 1\n",
    "    data.x[0,0] = 1\n",
    "    data.x[0,1] = 0\n",
    "else:\n",
    "    init_infect_rate_ = np.random.rand() * INIT_INFECT_RATE\n",
    "    x = torch.tensor([int(np.random.rand() < init_infect_rate_) for _ in range(data.num_nodes)])\n",
    "    data.x = torch.column_stack([x, 1*(x != 1)]).float()\n",
    "\n",
    "x_state = torch.zeros(data.num_nodes)\n",
    "x_state[torch.where(data.x[:,0]==1)] = INFECTED\n",
    "\n",
    "infection_chains = {}\n",
    "for node in range(data.num_nodes):\n",
    "    if x_state[node] == INFECTED:\n",
    "        infection_chains[node] = [node]\n",
    "\n",
    "for step in range(steps):\n",
    "    I_nodes = torch.where(x_state==INFECTED)[0].tolist()\n",
    "    for I_node in I_nodes:\n",
    "        for node in A[I_node].nonzero().flatten().tolist():\n",
    "            if node in I_nodes:\n",
    "                continue\n",
    "\n",
    "            if np.random.rand() < INFECTION_RATE:\n",
    "                if x_state[node] == IMMUNED:\n",
    "                    if np.random.rand() < 1 - IMMUNE_RATE:\n",
    "                        x_state[node] = INFECTED\n",
    "                        infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "                else:\n",
    "                    x_state[node] = INFECTED\n",
    "                    infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "        \n",
    "        if np.random.rand() < CURE_RATE:\n",
    "            x_state[I_node] = IMMUNED\n",
    "            del infection_chains[I_node]\n",
    "    \n",
    "data.infection_chains = infection_chains.copy()\n",
    "data.y = (x_state==INFECTED) * 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structure import Graph\n",
    "from train_model import modules\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_layer = 4\n",
    "config = {\n",
    "    'num_layer': num_layer,\n",
    "    'mode': 'gcn',\n",
    "    'epochs': 100,\n",
    "    'lr': 0.0005,\n",
    "    'model_dir': 'models/gcn-'+str(num_layer)+'-infection-sir.torch',\n",
    "    'nbclasses': 2,\n",
    "    'inter_feat_dim': 32,\n",
    "    'print_out_nb': 100,\n",
    "    'optimizer': 'adam'\n",
    "}\n",
    "num_layer= config['num_layer']\n",
    "mode = config['mode']\n",
    "epochs = config['epochs']\n",
    "lr = config['lr'] \n",
    "model_dir = config['model_dir']\n",
    "nbclasses = config['nbclasses']\n",
    "inter_feat_dim = config['inter_feat_dim']\n",
    "print_out_nb = config['print_out_nb']\n",
    "optimizer_label = config['optimizer']\n",
    "\n",
    "H0_dim = 2\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print('train {}'.format(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modules.Net1(num_node_features=H0_dim, num_classes=nbclasses, num_layers=num_layer, concat_features=False, conv_type='GraphConv')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    loss_ = []\n",
    "    acc_ = []\n",
    "    for data in train_set:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index)\n",
    "        acc = ((output.argmax(axis=1) == data.y) * 1.0).mean()\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_.append(float(loss))\n",
    "        acc_.append(float(acc))\n",
    "        optimizer.step()\n",
    "    losses.append(np.mean(loss_))\n",
    "    accs.append(np.mean(acc_))\n",
    "    \n",
    "\n",
    "    if (ep+1) % print_out_nb == 0:\n",
    "        loss_all = 0\n",
    "        acc_all = 0\n",
    "        for data in test_set:\n",
    "            output = model(data.x, data.edge_index)\n",
    "            loss = F.nll_loss(output, data.y)\n",
    "            loss_all += loss.item()\n",
    "            acc_all += ((output.argmax(axis=1) == data.y) * 1.0).mean()\n",
    "        \n",
    "        \n",
    "        output = model(val_data.x, val_data.edge_index)\n",
    "        loss_val = F.nll_loss(output, val_data.y).item()\n",
    "        acc_val = ((output.argmax(axis=1) == val_data.y) * 1.0).mean()\n",
    "        print(\"Ep:\", ep+1, \"Loss: \",loss_all / 20, \"Acc: \", acc_all / 20, \"Val loss: \", loss_val, \"Val acc: \", acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(accs)\n",
    "plt.legend(['loss', 'acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infection Chain Detection Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_oracle_ks_edge(data, model, skip_edge=False):\n",
    "    steps = 4\n",
    "    sim_steps = 1000\n",
    "    inf_hist = []\n",
    "    A = to_dense_adj(data.edge_index)[0]\n",
    "\n",
    "    infection_chains_list = []\n",
    "    for _ in range(sim_steps):\n",
    "        x_state = torch.zeros(data.num_nodes)\n",
    "        x_state[torch.where(data.x[:,0]==1)] = INFECTED\n",
    "\n",
    "        infection_chains = {}\n",
    "        for node in range(data.num_nodes):\n",
    "            if x_state[node] == INFECTED:\n",
    "                infection_chains[node] = [node]\n",
    "\n",
    "        for step in range(steps):\n",
    "            I_nodes = torch.where(x_state==INFECTED)[0].tolist()\n",
    "            for I_node in I_nodes:\n",
    "                for node in A[I_node].nonzero().flatten().tolist():\n",
    "                    if node in I_nodes:\n",
    "                        continue\n",
    "\n",
    "                    if np.random.rand() < INFECTION_RATE:\n",
    "                        if x_state[node] == IMMUNED:\n",
    "                            if np.random.rand() < 1 - IMMUNE_RATE:\n",
    "                                x_state[node] = INFECTED\n",
    "                                infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "                        else:\n",
    "                            x_state[node] = INFECTED\n",
    "                            infection_chains[node] = infection_chains[I_node].copy() + [node]\n",
    "                \n",
    "                if np.random.rand() < CURE_RATE:\n",
    "                    x_state[I_node] = IMMUNED\n",
    "                    del infection_chains[I_node]\n",
    "        inf_hist.append(((x_state==INFECTED) * 1).tolist())\n",
    "        infection_chains_list.append(infection_chains)\n",
    "\n",
    "    inf_hist = np.array(inf_hist)\n",
    "\n",
    "    infection_chains_prob_dict = {}\n",
    "    edges_prob_dict = {}\n",
    "    for infection_chains in infection_chains_list:\n",
    "        for key, val in zip(infection_chains.keys(), infection_chains.values()):\n",
    "            if key not in infection_chains_prob_dict:\n",
    "                infection_chains_prob_dict[key] = {}\n",
    "                edges_prob_dict[key] = {}\n",
    "\n",
    "            val = tuple(val)\n",
    "            if val not in infection_chains_prob_dict[key]:\n",
    "                infection_chains_prob_dict[key][val] = 1 / sim_steps\n",
    "            else:\n",
    "                infection_chains_prob_dict[key][val] += 1 / sim_steps\n",
    "\n",
    "            if not skip_edge:\n",
    "                edges = [(val[i], val[i+1]) for i in range(len(val) - 1)]\n",
    "                for edge in edges:\n",
    "                    if edge[0] == edge[1]: continue\n",
    "                    if edge not in edges_prob_dict[key]:\n",
    "                        edges_prob_dict[key][edge] = 1\n",
    "                    else:\n",
    "                        edges_prob_dict[key][edge] += 1\n",
    "\n",
    "\n",
    "    return infection_chains_prob_dict, edges_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_edge_igs = []\n",
    "acc_edge_igs_prod = []\n",
    "acc_top_ks_zero = []\n",
    "acc_top_ks_ab = []\n",
    "acc_top_ks_gamma = []\n",
    "acc_top_ks_02 = []\n",
    "oracle_ks_list = []\n",
    "oracle_edge_nos_list = []\n",
    "\n",
    "num_walks = 25\n",
    "threshold = 0.05\n",
    "np.random.seed(0)\n",
    "data_idxs  = np.random.choice(100, 20, replace=False)\n",
    "\n",
    "def compare_topk_groundtruth(real_top_k_max_walks_rels, inf_chain):\n",
    "    top_k_walk = [item[0] for item in real_top_k_max_walks_rels]\n",
    "\n",
    "    found = False\n",
    "    for k in range(len(top_k_walk)):\n",
    "        walk_drop_duplicate = [top_k_walk[k][0]]\n",
    "        for node in top_k_walk[k][1:]:\n",
    "            if walk_drop_duplicate[-1] != node:\n",
    "                walk_drop_duplicate.append(node)\n",
    "\n",
    "        if tuple(walk_drop_duplicate) == tuple(inf_chain): \n",
    "            found = True\n",
    "            k = k+1\n",
    "            break\n",
    "    if found == False: \n",
    "        k = float('inf')\n",
    "    return k\n",
    "\n",
    "for data_idx in data_idxs:\n",
    "    data = dataset[data_idx]\n",
    "    pos_correct_pred_nodes = sorted(list(set(data.y.nonzero().flatten().tolist()).intersection(set(model(data.x, data.edge_index).argmax(axis=1).nonzero().flatten().tolist()))))\n",
    "    \n",
    "    infection_chains_prob_dict, _ = mc_oracle_ks_edge(data, model, skip_edge=True)\n",
    "\n",
    "    for node_idx_to_explain in tqdm(np.random.choice(pos_correct_pred_nodes, min(200, len(pos_correct_pred_nodes)), replace=False)):\n",
    "        if len(data.infection_chains[node_idx_to_explain]) == 1: continue\n",
    "        inf_chain = data.infection_chains[node_idx_to_explain]\n",
    "\n",
    "        \n",
    "        edges_ig, edge_rels_ig = edge_ig(data, model, node_idx_to_explain, top_n=num_walks)        \n",
    "        edges_ig = [tuple(edge) for edge in edges_ig]\n",
    "        edges_ig_dict = dict(zip(edges_ig, edge_rels_ig))\n",
    "\n",
    "        walks_candidates = set(edges_ig)\n",
    "        for step in range(4):\n",
    "            walks_candidates_toadd = set()\n",
    "            for walk in walks_candidates:\n",
    "                for edge in edges_ig:\n",
    "                    if walk[-1] == edge[0]:\n",
    "                        walks_candidates_toadd.add(tuple(list(walk)+[edge[1]]))\n",
    "            walks_candidates = walks_candidates.union(walks_candidates_toadd)\n",
    "\n",
    "        walks_candidates_rels_sum = []\n",
    "        walks_candidates_rels_prod = []\n",
    "        for walk in walks_candidates:\n",
    "            rel_sum = 0\n",
    "            rel_prod = 1\n",
    "            for i in range(len(walk) - 1):\n",
    "                rel_sum += edges_ig_dict[(walk[i], walk[i+1])]\n",
    "                rel_prod *= edges_ig_dict[(walk[i], walk[i+1])]\n",
    "            walks_candidates_rels_sum.append([walk, rel_sum])\n",
    "            walks_candidates_rels_prod.append([walk, rel_prod])\n",
    "\n",
    "        top_walks_edge_ig = sorted(walks_candidates_rels_sum, key = lambda x: x[1], reverse=True)\n",
    "        k = compare_topk_groundtruth(top_walks_edge_ig, inf_chain)\n",
    "        acc_edge_igs.append(k)\n",
    "\n",
    "        top_walks_edge_ig = sorted(walks_candidates_rels_prod, key = lambda x: x[1], reverse=True)\n",
    "        k = compare_topk_groundtruth(top_walks_edge_ig, inf_chain)\n",
    "        acc_edge_igs_prod.append(k)\n",
    "        \n",
    "        rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = None, normalize=False)\n",
    "        real_top_k_max_walks_rels, real_top_k_min_walks_rels = approx_top_k_walk(num_walks, node_idx_to_explain, data, model, rel_components, X_fc, A, verbose=False)\n",
    "        k = compare_topk_groundtruth(real_top_k_max_walks_rels, inf_chain)\n",
    "        acc_top_ks_gamma.append(k)\n",
    "\n",
    "        rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'gamma', gammas = [0.2]*4, normalize=False)\n",
    "        real_top_k_max_walks_rels, real_top_k_min_walks_rels = approx_top_k_walk(num_walks, node_idx_to_explain, data, model, rel_components, X_fc, A, verbose=False)\n",
    "        k = compare_topk_groundtruth(real_top_k_max_walks_rels, inf_chain)\n",
    "        acc_top_ks_02.append(k)\n",
    "\n",
    "        rel_components, X_fc, A = get_rel_components(data=data, model=model,lrp_rule = 'pos-clip', gammas = None, normalize=False)\n",
    "        real_top_k_max_walks_rels, real_top_k_min_walks_rels = approx_top_k_walk(num_walks, node_idx_to_explain, data, model, rel_components, X_fc, A, verbose=False)\n",
    "        k = compare_topk_groundtruth(real_top_k_max_walks_rels, inf_chain)\n",
    "        acc_top_ks_ab.append(k)\n",
    "\n",
    "        k = compare_topk_groundtruth(infection_chains_prob_dict[node_idx_to_explain], inf_chain)\n",
    "        oracle_ks_list.append(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,2))\n",
    "x_range = 31\n",
    "plt.plot(np.arange(1,x_range), [np.mean(np.array(oracle_ks_list) <= i) for i in range(1, x_range)], '--', color='gray')\n",
    "plt.plot(np.arange(1,x_range), [np.mean(np.array(acc_top_ks_gamma) <= i) for i in range(1, x_range)], 'b-.')\n",
    "plt.plot(np.arange(1,x_range), [np.mean(np.array(acc_edge_igs) <= i) for i in range(1, x_range)], 'g-+')\n",
    "plt.plot(np.arange(1,x_range), [np.mean(np.array(acc_edge_igs_prod) <= i) for i in range(1, x_range)], '-')\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel('Walk Recall')\n",
    "plt.xlabel('K')\n",
    "plt.legend([r'oracle', r'AMP-ave (ours)', 'Edge-IG sum', 'Edge-IG prod'])\n",
    "\n",
    "plt.xlim(1,x_range-1)\n",
    "plt.ylim(0.4,1.01)\n",
    "plt.xticks([1,5,10,15,20,25,30])\n",
    "plt.savefig(\"imgs/infection_res_walk.svg\", dpi=600, format='svg',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sGNN-LRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65d5eb093fbec7e7bc52665d82a3cd76b3638a6de4797644d5d4a8277e42c4dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
